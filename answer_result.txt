### 📄 步骤 1/5: PDF解析与结构化提取

✅ 已完成

### ❓ 步骤 2/5: 问题理解与关键词提取

✅ 已完成

### 🔍 步骤 3/5: 相关段落检索

 ### 📊 步骤 4/5: 上下文构建与证据筛选

### 📝 步骤 5/5: 答案生成

## 📄 答案

      本论文的核心贡献是提出了AutoMLGen，一个基于大型语言模型（LLM）的自动机器学习框架，它通过结合蒙特卡洛图搜索（MCGS）和多分支聚合等创新组件，实现了对机器学习任务的高效自动化处理。该算法在MLE-Bench基准测试中表现出色，达到了最高68.12%的medal rate，并在多个任务域中优于现有基线模型。

### 核心贡献
AutoMLGen框架的核心创新在于其结构化搜索机制和知识重用策略。具体包括：
- **MCGS模块**：扩展自传统蒙特卡洛树搜索（MCTS），通过嵌入图结构来增强扩展阶段，支持跨分支参考和聚合，从而提升搜索效率和质量。
- **多分支聚合**：通过合并跨分支的高质量组件（如参考边和多分支聚合），促进多样性和稳定性，最终将medal rate从基础版本的36.36%提升至完整框架的68.12%。
- **适应性设计**：框架可适配不同LLM（如DeepSeek-R1、o4-mini和Gemini-2.5-pro），在图像、文本和表格数据任务中均保持稳定性能，如图5(a)所示，其中Gemini-2.5-pro在平均性能上表现最佳。

### 算法性能
AutoMLGen在多项指标上显著优于对比模型，具体数据如下：
- **整体性能**：在MLE-Bench的75个任务评估中，AutoMLGen使用DeepSeek-R1达到62.1±3.0的得分，并在关键指标如medal rate（36.4±1.2%）、gold medal rate（18.7±0.8%）和valid submission rate（96.4±0.4%）上表现最优（段落1）。
- **任务域比较**：如表5所示，在图像任务中，DeepSeek-R1在狗品种识别（Logloss: 0.3003）和组织病理学癌症检测（AUC: 0.9981）上领先，而Gemini-2.5-pro在导管线分类（AUC: 0.9403）和文档去噪（RMSE: 0.0165）中最佳，凸显了模型在不同领域的适应性。
- **消融分析**：逐步添加组件（如初级扩展、分支内演化、跨分支参考和多分支聚合）使medal rate从36.36%提升至59.09%，最终达到68.12%，证明了各组件对性能的贡献（段落3）。
- **时间演化**：如图5(b)所示，AutoMLGen的性能随运行时间增加而逐步提升，且在每个时间步均优于基线，归因于MCGS模块的有效交互和聚合机制（段落4）。
- **资源效率**：在单任务测试环境中，使用12小时时间预算和3次随机运行平均，框架在计算资源（32 vCPUs、230GB RAM、1 NVIDIA A800 GPU）下保持稳定输出（段落1）。

总体而言，AutoMLGen通过其创新架构和优化策略，在自动化机器学习任务中实现了高性能和强适应性，为LLM驱动的AutoML提供了可扩展解决方案。